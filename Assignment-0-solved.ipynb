{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXazklFIxu-",
        "colab_type": "text"
      },
      "source": [
        "**Code for Task 1:**\n",
        "\n",
        "> Only the initialization statement is modified to check the value of loss while varying hidden_size and number of epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e7O8LfiJUxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This code is the template for all the three tasks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFhzrS8kWkI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This code is the template for all the three tasks\n",
        "class NeuralNetwork():\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.weights_input_to_hidden = np.random.random((input_size, hidden_size))\n",
        "    self.weights_hidden_to_output = np.random.random((hidden_size, output_size))\n",
        "\n",
        "  # For Task 2, change the sigmoid function to tan-h and reLU here\n",
        "  ## TASK 2 CODE STARTS HERE\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5wATzkBYPFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def func(self, x, deriv = False):\n",
        "  # sigmoid\n",
        "      if deriv:\n",
        "         return x * (1 - x)\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "   #tanh \n",
        "    #f = np.tanh(x)\n",
        "    #if deriv:\n",
        "    #      return 1 - f**2\n",
        "    #return f\n",
        "   #relu \n",
        "  # if deriv:\n",
        "  #      if x.any()>0:\n",
        "   #         return 1\n",
        "    #    else:\n",
        "     #       return 0\n",
        "   #else:\n",
        "   # return x*(x>0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqjopS-NY5tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(self, train_x, train_y, num_epochs):\n",
        "    loss_dict = {}\n",
        "    for epoch in range(num_epochs):\n",
        "        # Forward prop\n",
        "        self.l0 = train_x\n",
        "        self.l1 = self.func(np.dot(self.l0, self.weights_input_to_hidden))\n",
        "        l2 = self.func(np.dot(self.l1, self.weights_hidden_to_output))\n",
        "\n",
        "        # Backprop\n",
        "        # Finding final and hidden layer losses\n",
        "        loss = train_y - l2\n",
        "        if epoch % 1000 == 0:\n",
        "          print('Epoch {}/{} \\tLoss:{}'.format(epoch+1, num_epochs, np.mean(np.abs(loss))))\n",
        "          #plt.plot(epoch+1,np.mean(loss))\n",
        "        \n",
        "        l2_delta = loss * self.func(l2, deriv = True)\n",
        "        l1_error = l2_delta.dot(self.weights_hidden_to_output.T)\n",
        "        l1_delta = l1_error * self.func(self.l1, deriv = True)\n",
        "        \n",
        "        # Optimizing weights\n",
        "        self.weights_hidden_to_output += self.l1.T.dot(l2_delta)\n",
        "        self.weights_input_to_hidden += self.l0.T.dot(l1_delta)\n",
        "\n",
        "        # Store loss in a dictionary\n",
        "        loss_dict[epoch] = np.abs(np.mean(loss))\n",
        "    return loss_dict\n",
        "        \n",
        "  def test(self, test_x):\n",
        "    self.l0 = test_x\n",
        "    self.l1 = self.func(np.dot(self.l0, self.weights_input_to_hidden))\n",
        "    output = self.func(np.dot(self.l1, self.weights_hidden_to_output))\n",
        "    if output < 0.5:\n",
        "      return 0\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY2DX_iqWp1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This code is the template for all the three tasks\n",
        "# Training Set\n",
        "arr_x = np.array([[0,0,0],\n",
        "                [1,1,1],\n",
        "                [1,0,0],\n",
        "                [0,0,1],\n",
        "                [1,1,0],\n",
        "                [1,0,1]])\n",
        "arr_y = np.array([[0],\n",
        "                 [1],\n",
        "                 [1],\n",
        "                 [1],\n",
        "                 [0],\n",
        "                 [0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi1zQzdMXxKK",
        "colab_type": "text"
      },
      "source": [
        "Only the following part of the code was modified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zDeFSN0WucY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = NeuralNetwork(input_size=3, hidden_size=5, output_size = 1)\n",
        "loss = nn.train(train_x = arr_x, train_y = arr_y, num_epochs =5000)\n",
        "plt.plot(list(loss.keys()),list(loss.values()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfgOmz6FX9U5",
        "colab_type": "text"
      },
      "source": [
        "**Code for Task 2**\n",
        "\n",
        "\n",
        "> To use the different activation functions, two functions were written and executed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuxZiTNSX886",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func1(self, x, deriv = False):\n",
        " \n",
        "   #tanh \n",
        "    f = np.tanh(x)\n",
        "    if deriv:\n",
        "          return 1 - f**2\n",
        "    return f\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO8Tj1qXYkF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def func2(self,x,deriv=False):\n",
        " #relu \n",
        " \n",
        "  if deriv:\n",
        "         if x.any()>0:\n",
        "           return 1\n",
        "         else:\n",
        "            return 0\n",
        "  else:\n",
        "   return x*(x>0)\n",
        "\n",
        "\n",
        "      \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwLLPnJsZbwz",
        "colab_type": "text"
      },
      "source": [
        "**Code for Task 3**\n",
        "\n",
        "> The training data for the model alone was changed in accordance to the truth table of the given equations.\n",
        " The input size was changed to 4 in the initilaization statement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avd_-eRQZa02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training Data for equation 1\n",
        "#1. F = !((A.B)+C) + D\n",
        "\n",
        "\n",
        "arr_x =np.array([[0,0,0,0],[0,0,0,1],[0,0,1,0],[0,0,1,1],[0,1,0,0],[0,1,0,1],[0,1,1,0],[0,1,1,1],[1,0,0,0],[1,0,0,1],[1,0,1,0],[1,0,1,1],\n",
        "        [1,1,0,0]])\n",
        "arr_y =np.array([[1],[1],[0],[1],[1],[1],[0],[1],[1],[1],[0],[1],[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "998iezRUaA0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training data for equation 2\n",
        "# F = !(A.B) xor !(C.D)\n",
        "\n",
        "\n",
        "arr_x =np.array([[0,0,0,0],[0,0,0,1],[0,0,1,0],[0,0,1,1],[0,1,0,0],[0,1,0,1],[0,1,1,0],[0,1,1,1],[1,0,0,0],[1,0,0,1],[1,0,1,0],[1,0,1,1],\n",
        "        [1,1,0,0]])\n",
        "arr_y =np.array([[0],[0],[0],[1],[0],[0],[0],[1],[0],[0],[0],[1],[1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y3atIHraIlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_task3 = NeuralNetwork(input_size=4, hidden_size =4, output_size = 1)\n",
        "loss = nn_task3.train(train_x = arr_x, train_y = arr_y, num_epochs = 5000)\n",
        "plt.plot(list(loss.keys()),list(loss.values()))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}